{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0040e0-88e8-45eb-a6ae-e0812440582c",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eed7795-40f3-45c4-bd4c-b6acf624a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\naman\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e8975-2e19-4131-8f06-2bd141a87478",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46bd267",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Abirate/english_quotes\")\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "df.sample(5)\n",
    "df.dropna(subset=['quote', 'author', 'tags'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29898622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quote'] = df['quote'].str.strip().str.lower()\n",
    "df['author'] = df['author'].str.strip().str.lower()\n",
    "\n",
    "df['tags'] = df['tags'].apply(lambda tags: [t.strip().lower() for t in tags if isinstance(t, str)])\n",
    "df.drop_duplicates(subset=['quote', 'author'], inplace=True)\n",
    "\n",
    "df['tags_str'] = df['tags'].apply(lambda x: ','.join(x) if isinstance(x, list) else '')\n",
    "df.to_csv(\"cleaned_quotes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb4aa9-1718-455e-a868-f900872109d9",
   "metadata": {},
   "source": [
    "### Model Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d642540-6b40-4d81-9ba6-85b7bb729fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer(df['quote'].iloc[0], truncation=True, padding='max_length', max_length=64)\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "examples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e40f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    if len(row['tags']) == 0:\n",
    "        continue\n",
    "    tag_query = f\"quotes about {random.choice(row['tags'])}\"\n",
    "    author_query = f\"quotes by {row['author']}\"\n",
    "    full_query = f\"{tag_query} by {row['author']}\"\n",
    "\n",
    "    examples.append(InputExample(texts=[tag_query, row['quote']]))\n",
    "    examples.append(InputExample(texts=[full_query, row['quote']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b79ef95-1c22-4c8c-a20a-9bc46394371e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696341907be04f57848c15fb704103d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naman\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 17:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933179d2085d4fbd925dcef5fe636efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(examples, shuffle=True, batch_size=32)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    warmup_steps=100,\n",
    "    output_path='fine_tuned_miniLM_quotes'\n",
    ")\n",
    "\n",
    "model = SentenceTransformer('fine_tuned_miniLM_quotes')\n",
    "\n",
    "quote_embeddings = model.encode(df['quote'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e4cba-2455-4151-b384-93d01e53a0e8",
   "metadata": {},
   "source": [
    "### Building the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "021b6e6b-a0ff-4aaa-bf21-39a079a3d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = quote_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(quote_embeddings))\n",
    "faiss.write_index(index, \"quotes_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f750cd12-febd-4a00-a099-efd2773bd2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HF_API_TOKEN = os.getenv(\"HF_API_TOKEN\")\n",
    "\n",
    "def query_huggingface_llm(payload, model_id=\"HuggingFaceH4/zephyr-7b-beta\"):\n",
    "    API_URL = f\"https://api-inference.huggingface.co/models/{model_id}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {HF_API_TOKEN}\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"HTTP error occurred: {err}\")\n",
    "        print(f\"Response content: {response.text}\")\n",
    "        if response.status_code == 503:\n",
    "            print(\"Model is currently loading, please retry in a few seconds.\")\n",
    "        return None\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred: {err}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2835cb71-d8b8-4bb0-a07d-49a9157f8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_quotes(user_query, top_k=5):\n",
    "    query_embedding = model.encode([user_query])\n",
    "    \n",
    "    distances, indices = index.search(np.array(query_embedding).astype('float32'), top_k) # Ensure float32 for FAISS consistency\n",
    "\n",
    "    results = []\n",
    "    for idx, score in zip(indices[0], distances[0]):\n",
    "        raw_tags = df.iloc[idx].get('tags', '[]')\n",
    "        if isinstance(raw_tags, str):\n",
    "            try:\n",
    "                tags = json.loads(raw_tags)\n",
    "            except json.JSONDecodeError:\n",
    "                tags = [t.strip() for t in raw_tags.split(',')] if raw_tags else []\n",
    "        else:\n",
    "            tags = raw_tags if isinstance(raw_tags, list) else []\n",
    "\n",
    "\n",
    "        results.append({\n",
    "            \"quote\": df.iloc[idx]['quote'],\n",
    "            \"author\": df.iloc[idx]['author'],\n",
    "            \"tags\": tags,\n",
    "            \"score\": round(float(score), 4)\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f379fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_query, retrieved_quotes):\n",
    "    if not retrieved_quotes:\n",
    "        return \"I couldn't find any relevant quotes for your query. Please try rephrasing.\"\n",
    "\n",
    "    context_quotes = \"\\n\".join([\n",
    "        f\"- \\\"{q['quote']}\\\" (Author: {q['author']}, Tags: {', '.join(q['tags'])})\"\n",
    "        for q in retrieved_quotes\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"You are an intelligent assistant that provides insightful responses based on given quotes.\n",
    "The user is looking for quotes related to: \"{user_query}\"\n",
    "\n",
    "Here are some relevant quotes I found:\n",
    "{context_quotes}\n",
    "\n",
    "Based on the above quotes and the user's request, provide a concise and helpful answer. You can either directly present the most relevant quote(s), or synthesize information from them to answer the user's implicit question. If the quotes don't directly answer the query, explain that but still provide the most relevant ones.\n",
    "\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": 700,\n",
    "            \"temperature\": 0.7,\n",
    "            \"do_sample\": True,\n",
    "            \"return_full_text\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    llm_response = query_huggingface_llm(payload)\n",
    "\n",
    "    if llm_response and isinstance(llm_response, list) and len(llm_response) > 0:\n",
    "        generated_text = llm_response[0].get('generated_text', '').strip()\n",
    "        if generated_text.startswith(prompt.strip()):\n",
    "            generated_text = generated_text[len(prompt.strip()):].strip()\n",
    "        return generated_text\n",
    "    else:\n",
    "        return \"I apologize, but I couldn't generate a coherent response at this moment. Please try again or rephrase your query.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a3ff44e-3574-4c84-aa7c-60fe516db5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, there are no direct quotes about insanity attributed to Einstein. However, the quote \"no great mind has ever existed without a touch of madness\" by Aristotle suggests that Einstein's brilliance may have had a touch of insanity. Additionally, Albert Einstein once said, \"I have erased this line between dancer and choreographer.\" While this quote is not directly related to insanity, it does highlight Einstein's unique perspective and creativity, which could be seen as a sign of genius, or perhaps a touch of madness. Nevertheless, the quote \"insanity is doing the same thing, over and over again, but expecting different results\" is often misattributed to Einstein, although it is unclear whether he actually said it. Regardless, this quote speaks to the idea of persistent and unconventional thinking, which could be seen as both a hallmark of genius and a potential indicator of insanity.\n"
     ]
    }
   ],
   "source": [
    "query = \"quotes about insanity attributed to Einstein\"\n",
    "top_k_results = retrieve_quotes(query)\n",
    "rag_response = generate_response(query, top_k_results)\n",
    "\n",
    "print(rag_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
